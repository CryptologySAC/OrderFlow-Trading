# Signal Validation Process Documentation

## Overview

The signal validation system tracks detector performance by monitoring real-time signals and their outcomes over time. This document explains the complete validation flow, file structure, and statistical analysis methodology.

## Signal Validation Flow

### 1. Signal Generation

- Detectors (Absorption, Exhaustion, DeltaCVD) analyze real-time market data
- When conditions are met, a signal is generated with all parameter values
- Signal includes: timestamp, detector type, side (buy/sell), price, and all configuration parameters

### 2. Signal Tracking

- All generated signals are automatically tracked for 90 minutes
- Price movements are monitored at 5min, 15min, and 1hr intervals
- Two key thresholds are checked:
    - **Target (TP)**: 0.7% movement in signal direction
    - **Stop Loss (SL)**: 0.35% movement against signal direction

### 3. Outcome Determination

The system determines signal outcomes using strict chronological logic:

```
IF signal reaches 0.7% TP within 90 minutes:
  IF 0.35% SL was hit BEFORE reaching TP:
    Classification = "SL" (but still successful)
  ELSE:
    Classification = "TP" (direct success)
  Action: Write to SUCCESS file (validation file)

ELSE:
  Classification = "FALSE" (failed to reach target)
  Action: Do NOT write to any file (false signal)
```

## File Structure

### Validation Files (All Generated Signals)

- **Location**: `logs/signal_validation/{detector}_validation_{date}.csv`
- **Contains**: Every signal generated by the detector, regardless of outcome
- **Purpose**: Complete detector activity log for debugging and analysis

### Success Files (Target-Reaching Signals Only)

- **Location**: `logs/signal_validation/{detector}_validation_{date}.csv` (same file, filtered subset)
- **Contains**: Only signals that reached 0.7% TP within 90 minutes
- **Two categories**:
    - `TP_SL = "TP"`: Reached target directly without hitting stop loss
    - `TP_SL = "SL"`: Hit stop loss first but still reached target eventually
- **Purpose**: Successful signal analysis for parameter optimization

### Key Point: File Relationship

- SUCCESS signals are a **filtered subset** of VALIDATION signals
- All success signals appear in both datasets
- For analysis, success signals must be **filtered out** from validation to get true "false" signals

## Statistical Analysis Requirements

### Primary Analysis: Success vs False Signals

**Objective**: Identify parameter settings that statistically differentiate successful signals from false signals.

**Data Preparation**:

```
Success Dataset = signals with TP_SL value (reached 0.7% target)
False Dataset = validation signals WITHOUT TP_SL value (never reached target)
```

**Statistical Methods**:

1. **Cohen's d Effect Size**: Measure parameter difference magnitude
    - d > 0.8 = Large effect (practically significant)
    - d > 0.5 = Medium effect (moderately significant)
    - d > 0.2 = Small effect (minimally significant)

2. **Statistical Significance Testing**: Confirm differences aren't random
3. **Parameter Range Analysis**: Identify optimal value ranges for each parameter

### Secondary Analysis: TP vs SL Success Patterns

**Objective**: Determine if stop loss threshold (0.35%) is appropriate.

**Analysis**:

- Compare parameter patterns between TP and SL successful signals
- If SL signals show strong patterns, consider adjusting stop loss threshold
- Goal: Maximize true positives while minimizing false stops

### Parameter Categories to Analyze

**All detectors share common parameters**:

- `minTradesPerSec`, `minVolPerSec`, `signalThreshold`
- `eventCooldownMs`, `enhancementMode`, `confidence`

**Detector-specific parameters**:

**Absorption Detector** (~15 parameters):

- Volume thresholds, zone detection, price efficiency ratios
- Passive vs aggressive volume analysis parameters

**Exhaustion Detector** (~20 parameters):

- Volume exhaustion thresholds, reduction factors, momentum parameters
- Market structure analysis settings

**DeltaCVD Detector** (~10 parameters):

- CVD imbalance thresholds, timeframe analysis, institutional detection

## Event Grouping for Cooldown Analysis

### Problem: Multiple Signals Per Event

- Detectors use `eventCooldownMs` to prevent signal spam
- Single market event can generate multiple signals within cooldown period
- These are the SAME event, not independent signals

### Solution: Event Grouping

**Grouping Logic**:

```
Group signals by:
1. Detector type
2. Signal side (buy/sell)
3. Price proximity (within tick size variations)
4. Timestamp proximity (within cooldown period)
```

**Analysis Approach**:

- Treat grouped signals as single event for statistical analysis
- Use the first signal's parameters as representative
- Success/failure determined by ANY signal in group reaching target
- Prevents cooldown bias in statistical analysis

### Cooldown Statistical Treatment

- **Cooldown is NOT a success factor** - it's spam prevention
- Group analysis ensures cooldown doesn't artificially inflate/deflate success rates
- Focus analysis on market conditions and detector parameters, not timing artifacts

## Analysis Workflow

### Phase 1: Data Preparation

1. Load validation files for all three detectors
2. Separate success signals from false signals
3. Group signals by events using cooldown logic
4. Validate data integrity and parameter completeness

### Phase 2: Statistical Analysis

1. Calculate Cohen's d for each parameter across success vs false signals
2. Identify parameters with d > 0.5 (medium+ effect size)
3. Perform significance testing on identified parameters
4. Generate optimal parameter ranges for high-performing settings

### Phase 3: Optimization Recommendations

1. Propose new configuration values based on statistical findings
2. Validate recommendations don't break detector logic
3. Document confidence levels and expected performance improvements
4. Prepare A/B testing methodology for validation

## Expected Outcomes

**High-Impact Parameters**: Parameters showing strong statistical separation between success/false signals should be optimized first.

**Detector-Specific Insights**: Each detector likely has unique optimal settings based on market mechanics they detect.

**Success Rate Improvements**: Statistical optimization should increase success rates while maintaining signal quality and reducing false positives.

**Risk Management**: Analysis should validate that recommended settings don't increase downside risk or create unstable detector behavior.
